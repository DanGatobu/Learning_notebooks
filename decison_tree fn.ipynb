{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import determine_type_of_feature\n",
    "\n",
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique (label_column)\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# 1.2 Classify\n",
    "def classify_data(data):\n",
    "    label_column=data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index=counts_unique_classes.argmax()\n",
    "    classification=unique_classes [index]\n",
    "    return classification\n",
    "# 1.3 Potential splits?\n",
    "def get_potential_splits(data):\n",
    "    potential_splits=[]\n",
    "    _,n_columns= data.shape\n",
    "    for column_index in range(n_columns - 1): # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique (values)\n",
    "        potential_splits [column_index] = unique_values\n",
    "    return potential_splits\n",
    "#example\n",
    "def predict_example(example, tree):\n",
    "    question=list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, valuq = question.split(\" \")\n",
    "    # ask question\n",
    "    if comparison_operator == \"<\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer= tree [question][0]\n",
    "        else:\n",
    "            answer tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example [feature_name]) == value:\n",
    "            answer=tree [question][0]\n",
    "        else:\n",
    "            answer = tree [question] [1]\n",
    "    #base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    #recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "    return predict_example (example, residual_tree)\n",
    "\n",
    "def decision_tree_predictions (test_df, tree):\n",
    "    predictions = test_df.apply(predict_example, args=(tree,), axis=1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    label_column= data[:, -1]\n",
    "    _,counts = np.unique(label_column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy=sum(probabilities -np.log2 (probabilities))\n",
    "    return entropy\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    overall_entropy = (p_data_below* calculate_entropy(data_below)+p_data_above*calculate_entropy(data_above))\n",
    "                                                \n",
    "    return overall_entropy\n",
    "\n",
    "\n",
    "def determine_best_split (data, potential_splits):\n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits [column_index]:\n",
    "            data_below,data_above=split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy=calculate_overall_entropy(data_below, data_above)\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column= column_index\n",
    "                best_split_value = value\n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "def split_data(data, split_column, split_value):\n",
    "    split_column_values = data[:, split_column]\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature== \"continuous\":\n",
    "        data_below= data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values > split_value]\n",
    "#feature is categorical\n",
    "    else:\n",
    "        data_below= data[split_column_values = split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    return data_below,data_above\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decision_tree_algorithm (df, counter=0, min_samples=2, max_depth=5):\n",
    "#data preparations.\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS= df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data=df.values\n",
    "    else:\n",
    "        data = df\n",
    "#base cases\n",
    "        if (check_purity (data)) or (len (data) <min_samples) or (counter ==max_depth):\n",
    "            classification=classify_data(data)\n",
    "            return classification\n",
    "# recursive part\n",
    "        else:\n",
    "            counter + 1\n",
    "\n",
    "#helper functions\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value=determine_best_split(data, potential_splits)\n",
    "            data_below, data_above=split_data(data, split_column, split_value)\n",
    "#check for empty data\n",
    "        if len (data_below) == 0 or len(data_above) == 0:\n",
    "            classification=classify_data(data)\n",
    "            return classification\n",
    "#determine question.\n",
    "        feature_name = COLUMN_HEADERS [split_column]\n",
    "        type_of_feature = FEATURE_TYPES [split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "# feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "#instantiate sub-tree\n",
    "            sub_tree={question: []}\n",
    "#find answers (recursion)\n",
    "            yes_answer=decision_tree_algorithm (data_below, counter, min_samples, max_depth)\n",
    "            no_answer=decision_tree_algorithm (data_above, counter, min_samples, max_depth)\n",
    "# If the answers are the same, then there is no point in asking the gestion.\n",
    "#This could happen when the data is classified even though it is not pure\n",
    "#yet (min_samples or max_depth base case).\n",
    "            if yes_answer == no_answer:\n",
    "                sub_tree=yes_answer\n",
    "            else:\n",
    "                sub_tree[question].append (yes_answer)\n",
    "                sub_tree [question].append (no_answer)\n",
    "    return sub_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
